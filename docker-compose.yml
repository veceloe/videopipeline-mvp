services:
  zookeeper:
    image: bitnami/zookeeper:3.9
    platform: linux/amd64
    ports:
      - "2181:2181"
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"

  kafka:
    image: bitnami/kafka:3.7
    platform: linux/amd64
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CFG_MESSAGE_MAX_BYTES: 10000000
      ALLOW_PLAINTEXT_LISTENER: "yes"
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CFG_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_CFG_ZOOKEEPER_CONNECTION_TIMEOUT_MS: 30000
      KAFKA_CFG_ZOOKEEPER_SESSION_TIMEOUT_MS: 30000
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  minio:
    image: quay.io/minio/minio:latest
    platform: linux/amd64
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5

  ytsaurus:
    image: ghcr.io/ytsaurus/local:stable-spyt
    platform: linux/amd64
    shm_size: "2g"
    environment:
      YT_USE_SINGLETON: "1"
      YT_ENABLE_HTTP_PROXY: "1"
    ports:
      - "80:80"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  ytsaurus-ui:
    build:
      context: .
      dockerfile: Dockerfile
    image: local-ytsaurus-ui:latest
    platform: linux/amd64
    depends_on:
      ytsaurus:
        condition: service_healthy
    ports:
      - "8080:80"
    volumes:
      - ./clusters-config.json:/opt/app/clusters-config.json:ro
      - ./stages:/opt/app/stages:ro
    environment:
      - NODE_ENV=production
      - APP_ENV=production
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 10s
      timeout: 5s
      retries: 5

  spark:
    image: bitnami/spark:3.3.2
    platform: linux/amd64
    depends_on:
      kafka:
        condition: service_healthy
      ytsaurus:
        condition: service_healthy
      minio:
        condition: service_healthy
    environment:
      SPARK_MODE: driver
    volumes:
      - ./spark-app/target/scala-2.12/videopipeline-assembly-0.1.0.jar:/opt/spark/app/videopipeline.jar
      - ./secrets:/opt/spark/secrets:ro
      - ./tmp/spark-checkpoints:/tmp/spark-checkpoints
    command: >
      spark-submit
        --class VideoStreamProcessor
        --master local[*]
        /opt/spark/app/videopipeline.jar

  producer:
    build: ./producer
    platform: linux/amd64
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./media:/media

volumes:
  minio-data: